{
    "collab_server" : "",
    "contents" : "---\ntitle: \"p8105_hw5_ym2649\"\nauthor: \"Yutian Mu\"\ndate: \"10/31/2017\"\noutput: html_document\n---\n\n```{r read_library}\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(rvest)\nlibrary(httr)\nlibrary(forcats)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(viridis)\n```\n\n\n###problem 1\nSubway stations in NYC have multiple entrances; data on this page contains information on the entrances for each station.\n\nUsing the State of New York API, read the complete dataset using functions in httr. By default, the API will return only the first 1000 entries, so using the GET option query = list($limit= 2000) in your request will be useful.\n```{r read_nycdata}\nnyc_station = GET(\"https://data.ny.gov/resource/hvwh-qtfg.csv\",query = list(\"$limit\"= 2000)) %>%\ncontent(\"parsed\")\n```\n\nAfter you’ve read the data, clean it up: retain variables on station name, entrance latitude and longitude, East/West street, North/South street, and corner.\n```{r tidy_nycdata}\nnyc_tidy = nyc_station %>%\nselect(station_name,entrance_latitude,entrance_longitude,east_west_street,north_south_street,corner)\n```\n\nMake a plot showing the number of entrances for each subway station. Restrict your plot to stations that have more than 10 entrances, and order stations according to the number of entrances.\n```{r nyc_plot}\nnyc_tidy %>%\n  group_by(station_name) %>%\n  summarize(n_entrance = n()) %>%\n  filter(n_entrance > 10) %>% \n  ungroup() %>%\n  mutate(station_name = fct_reorder(station_name, n_entrance)) %>% \n  ggplot(aes(x = station_name, y = n_entrance)) + \n  geom_bar(stat = \"identity\", fill = \"blue\", alpha = .6) +\n  coord_flip()\n```  \n\nOverall (not only in stations that have more than 10 entrances), how many subway station names contain the abbreviation “St”? How many end with “St”?\n\nAs shown below, there are **`r filter(nyc_tidy,str_detect(station_name, \"St\")) %>% summarize(n_distinct(station_name))`** subway station names contain the abbreviation “St”, and **`r filter(nyc_tidy,str_detect(station_name, \"St$\")) %>% summarize(n_distinct(station_name))`** end with \"St\".\n\n```{r nyc_entrance}\nnyc_tidy %>%\n filter(str_detect(station_name, \"St\")) %>%\n summarize(n_distinct(station_name))\n \nnyc_tidy %>%\n filter(str_detect(station_name, \"St$\")) %>%\n summarize(n_distinct(station_name))\n```\n\n###problem 2\nI’m curious about how many people watched each episode of “Game of Thrones” over the past 7 seasons. Find these data online and import them into R using functions in rvest. Taking the time to find data that’s pretty close to the format you want is worth a bit of effort; wikipedia is a good place to start.\n```{r read_thrones}\nurl = \"https://en.wikipedia.org/wiki/Game_of_Thrones\"\nthrones_episode = read_html(url) \nthrones_episode_table = (thrones_episode %>% html_nodes(css = \"table\"))[[4]]%>%\nhtml_table() %>%\n.[,-1] %>%\nas_tibble()\n```\n\nAfter you’ve found and read the data, make sure they’re tidy. In your final dataset, include variables for season, episode, and viewers; also create a unique episode ID of the form SX_EYY where X and Y are season or episode numbers.\n```{r tidy_thrones}\nthrones_tidy = thrones_episode_table %>%\n  clean_names() %>%\n  gather(key=episode, value=viewers, ep_1:ep_10) %>%\n  separate(episode, into = c(\"remove\", \"episode\"), sep = \"_\") %>%\n  select(-average,-remove) %>%\n  mutate(episode_id = str_c(\"S\",season,\"_E\",episode)) %>% \n  mutate(viewers = as.numeric(viewers)) %>%\n  filter(viewers !=\"NA\") %>%\n  select(episode_id,season,episode,viewers) %>%\n  arrange(season)\n```\n\nMake a plot that shows the number of viewers for each episode of each season.\n```{r thrones_plot}\nthrones_tidy %>%\nggplot(aes(x = season, y = viewers, fill=episode)) + geom_bar(stat=\"identity\",position=\"dodge\") + labs(title=\"Number of Viewers for Each Episode of Each Season\")\n```\n\nMake a boxplot of the number of viewers for each episode of each season.\n```{r boxplot}\nseason1 = filter(thrones_tidy,season == \"1\")$viewers\nseason2 = filter(thrones_tidy,season == \"2\")$viewers\nseason3 = filter(thrones_tidy,season == \"3\")$viewers\nseason4 = filter(thrones_tidy,season == \"4\")$viewers\nseason5 = filter(thrones_tidy,season == \"5\")$viewers\nseason6 = filter(thrones_tidy,season == \"6\")$viewers\nseason7 = filter(thrones_tidy,season == \"7\")$viewers\n\n\nseason_viewer = data_frame(\n    insulin = c(season1,season2,season3,season4,season5,season6,season7),\n    ind = c(rep(1, length(season1)),\n                    rep(2, length(season2)),\n                    rep(3, length(season3)),\n                    rep(4, length(season4)),\n                    rep(5, length(season5)),\n                    rep(6, length(season6)),\n                    rep(7, length(season7)))\n)\n\nseason_viewer = season_viewer %>% \n  mutate(ind = factor(ind), \n         ind = fct_recode(ind,\n                          \"season1\" = \"1\",\n                          \"season2\" = \"2\",\n                          \"season3\" = \"3\",\n                          \"season4\" = \"4\",\n                          \"season5\" = \"5\",\n                          \"season6\" = \"6\",\n                          \"season7\" = \"7\"))\n\nseason_viewer %>% \n  ggplot(aes(x = ind, y = insulin)) + geom_boxplot()\n```\n\nFit a linear model that treats number of viewers in each episode as a response and season as a categorical predictor; make season 4 the reference season. Present and discuss the results of your modeling.\n\n```{r linear_model}\nseason_viewer = season_viewer %>% \n  mutate(ind = factor(ind), \n         ind = fct_recode(ind,\n                          \"season1\" = \"1\",\n                          \"season2\" = \"2\",\n                          \"season3\" = \"3\",\n                          \"season4\" = \"4\",\n                          \"season5\" = \"5\",\n                          \"season6\" = \"6\",\n                          \"season7\" = \"7\"),\n        ind = fct_relevel(ind, \"season4\"))\n         \nseason_viewer %>% \n  lm(insulin ~ ind, data = .)%>% \n  broom::tidy() %>% \n  select(-std.error, -statistic) %>% \n  knitr::kable(digits = 3)\n```\nhigher\n\n###probllem 3\n```{r read_dynamite}\nread_page_reviews <- function(url) {\n  \n  h <- read_html(url)\n  \n  title <- h %>%\n    html_nodes(\"#cm_cr-review_list .review-title\") %>%\n    html_text()\n  \n  stars <- h %>%\n    html_nodes(\"#cm_cr-review_list .review-rating\") %>%\n    html_text() %>%\n    str_extract(\"\\\\d\") %>%\n    as.numeric()\n  \n  text = h %>%\n    html_nodes(\".review-data:nth-child(4)\") %>%\n    html_text()\n  \n  data_frame(title, stars, text)\n}\n\nurl_base <- \"https://www.amazon.com/product-reviews/B00005JNBQ/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=\"\nurls <- paste0(url_base, 1:100)\n\ndynamite_reviews <- map(urls, ~read_page_reviews(.x)) %>% \n  bind_rows\n```\n\nInspect and describe the resulting dataset. What variables are included? Has the scraping been successful?\nThe resulting dataset including variables of `r names(dynamite_reviews)`.\"title\" represents the title of comments, \"stars\" represents how many stars the viewers are given, and \"text\" represents the content of the comments. \n\nCreate a tidy text dataset from the above using the text in the reviews. Use words as the token and remove stop words.\n```{r tidy_dynamite}\ndynamite_reviews = dynamite_reviews %>%\n  mutate(dynamite_num = row_number()) \n\ndata(stop_words)\ndynamite_words = dynamite_reviews %>%\n  unnest_tokens(word, text) %>%\n  anti_join(stop_words)\n```\n\nWhat words are most frequently used in five-star reviews? In 1-star reviews?\n\nAs shown below, the word \"movie\" is most frequently used in both five-star and 1-star reviews.\n```{r freq_review}\ndynamite_words %>% \n  filter(stars == \"5\") %>%\n  count(word,sort=TRUE) %>%\n  top_n(1)\n  \ndynamite_words %>% \n  filter(stars == \"1\") %>%\n  count(word,sort=TRUE) %>%\n  top_n(1)\n```\n\nMake a plot that shows the (approximate) log odds ratio for word appearance comparing 1-star reviews to 5-star reviews; include the 10 words with the most extreme log ORs in both directions.\n```{r log_plot}\nword_ratio = dynamite_words %>% \n  filter(stars %in% c(\"1\",\"5\")) %>% \n  mutate(stars=recode(stars,`1`=\"star1\",`5`=\"star5\")) %>%\n  count(word, stars) %>%\n  spread(stars, n) %>% \n  mutate(star1=as.numeric(star1),star5=as.numeric(star5)) %>%\n  filter(star1 !=\"NA\",star5 !=\"NA\") %>%\n  mutate(star1_odds = (star1 + 1) / (sum(star1) + 1),\n    star5_odds = (star5 + 1) / (sum(star5) + 1),\n    log_OR = log(star1_odds / star5_odds))\n\nword_ratio %>%\n  mutate(pos_log_OR = ifelse(log_OR > 0, \"star1 > star5\", \"star5 > star1\")) %>% \n  group_by(pos_log_OR) %>%\n  top_n(10, abs(log_OR)) %>%\n  ungroup() %>%\n  mutate(word = fct_reorder(word, log_OR)) %>%\n  ggplot(aes(x=word, y=log_OR, fill=pos_log_OR)) + \n  geom_col() +\n  coord_flip() +\n  ylab(\"log odds ratio (star1/star5)\") +\n  scale_fill_discrete(name = \"\")  \n``` \n\n  \nConduct a sentiment analysis of the review texts; make a plot of your results and include the star rating in your graphic. What is the most positive review? The most negative review?\n```{r sentiment}\nbing_sentiments = get_sentiments(\"bing\")\n\ndynamite_sentiments = dynamite_words %>% \n  inner_join(.,bing_sentiments) %>% \n  count(dynamite_num, sentiment) %>% \n  spread(sentiment, n, fill = 0) %>% \n  mutate(sentiment = positive - negative) %>% \n  select(dynamite_num, sentiment)\n\ndynamite_sentiments = \n  right_join(dynamite_reviews, dynamite_sentiments, \n             by = \"dynamite_num\") \n```\n\nAs shown below, the most positive review is \"You must watch this movie\" and the most negative review is \"wow.\".\n```{r sentiment_rank}\ndynamite_sentiments %>%\n  mutate(sentiment_rank = min_rank(desc(sentiment))) %>%\n  filter(sentiment_rank==\"1\") \n  \ndynamite_sentiments %>%\n  mutate(sentiment_rank = min_rank(sentiment)) %>%\n  filter(sentiment_rank==\"1\") \n```\n\n```{r sentiment_plot}\ndynamite_sentiments %>%\n  mutate(stars=recode(stars,`1`=\"star1\",`2`=\"star2\",`3`=\"star3\",`4`=\"star4\",`5`=\"star5\"),\n    dynamite_num = factor(dynamite_num),\n    dynamite_num = fct_reorder(dynamite_num, sentiment)) %>% \n  ggplot(aes(x = dynamite_num, \n             y = sentiment, fill = stars , color = stars)) + \n  geom_bar(stat = \"identity\") + \n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank()) +\n  scale_fill_viridis(discrete = TRUE) + \n  scale_color_viridis(discrete = TRUE) \n```\n\n\n\n",
    "created" : 1510071592557.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1999676005",
    "id" : "570C3237",
    "lastKnownWriteTime" : 1510013588,
    "last_content_update" : 1510013588,
    "path" : "~/Documents/data_science/p8105_hw5_ym2649/p8105_hw5_ym2649.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}